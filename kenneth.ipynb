{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting csv into pandas dataframe\n",
    "\n",
    "Converting the **MERGEDXXXX_YY_PP.csv** files to dataframes with `read_csv()` causes an error regarding mixed types in columns. I'm using the `low_memory=False` argument to continue, but should consider using the `converters` or `dtype` args.\n",
    "\n",
    "With `converters`:    \n",
    "```Python\n",
    "def convert_dtype(x):\n",
    "    if not x:\n",
    "        return ''\n",
    "    try:\n",
    "        return str(x)   \n",
    "    except:        \n",
    "        return ''\n",
    "\n",
    "pd.read_csv('file.csv',converters={'first_column': convert_dtype,'second_column': convert_dtype})\n",
    "```\n",
    "\n",
    "With `dtype`:\n",
    "```Python\n",
    "pd.read_csv('file.csv', dtype={'first_column'='string', 'second_column'='string'})\n",
    "```\n",
    "\n",
    "The problem with either of these approaches in this context is that this dataset is wide (2000+ columns) and a lot of columns seem to have mixed columns. I will research how to solve this problem without ignoring memory concerns.\n",
    "\n",
    "The advantage we have when using `low_memory=False` is that the dataset is not large (6000+ rows), so the converstion from csv to dataframe is quick (~80ms on my machine)\n",
    "\n",
    "Reference: <a href=\"https://www.roelpeters.be/solved-dtypewarning-columns-have-mixed-types-specify-dtype-option-on-import-or-set-low-memory-in-pandas/\">dtype warning: columns have mixed types</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18 = pd.read_csv(\"data/MERGED2018_19_PP.csv\",low_memory=False)\n",
    "dfc18 = df18.copy() # create a copy of original df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to drop all fully empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original '18 shape: (6806, 2044) \n",
      "      after dropna: (6806, 711)\n"
     ]
    }
   ],
   "source": [
    "dfc18 = dfc18.dropna(axis='columns',how='all')\n",
    "print(f'original \\'18 shape: {df18.shape} \\n      after dropna: {dfc18.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We removed 1333 fully empty columns. Note: *We should probably inspect what columns they are in case the null values provide some sort of insight*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's filter which schools we are focused on (4 year institutions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2725, 711)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_4year = dfc18['HIGHDEG'] >= 3\n",
    "dfc18_4yr = dfc18[is_4year]\n",
    "dfc18_4yr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got 2725 4-year schools. Let's see how many columns have null values, and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfc18_4yr.columns[dfc18.isnull().any() == True].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_co = pd.read_csv(\"data/Most-Recent-Cohorts-All-Data-Elements.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6806, 2045)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_co.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
